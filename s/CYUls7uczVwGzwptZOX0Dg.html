<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="applicable-device" content="pc,mobile">
  <meta name="keywords" content="ELK,Rsyslog,Nginx,ELK,Agent,运维,运维博客,运维开发,自动化,云计算,ops,sre,linux,devops,cloud" />
  <meta name="description" content="ELK日志系统之使用Rsyslog快速方便的收集Nginx日志" />
  <link rel="stylesheet" href="/css/style.min.css" media="screen" type="text/css" />
  <link rel="shortcut icon" href="https://blz.nosdn.127.net/sre/posts/images/favicon.ico" />

  <!-- Begin SEO tag -->
  <title>ELK日志系统之使用Rsyslog快速方便的收集Nginx日志</title>
  <meta property="og:locale" content="zh_CN" />
  <meta property="og:site_name" content="运维咖啡吧" />
  <meta property="og:url" content="https://ops-coffee.cn/" />
  <meta property="og:title" content="ELK日志系统之使用Rsyslog快速方便的收集Nginx日志" />
  <meta property="og:description" content="ELK日志系统之使用Rsyslog快速方便的收集Nginx日志" />
  <link rel="canonical" href="https://ops-coffee.cn/" />
  <!-- End SEO tag -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145167079-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-145167079-1');
  </script>

  <!--
  <script data-ad-client="ca-pub-8944257246828217" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  -->
</head>

<body>
  <header>
    <div class="inner">
      <a href="https://ops-coffee.cn/">
        <h1>运维咖啡吧</h1>
      </a>
      <h2>追求技术的道路上，我从不曾停下脚步</h2>
    </div>
  </header>

  <div id="content-wrapper">
    <div class="inner clearfix">
      <section id="main-content">
      
        <h1 id="art-title">ELK日志系统之使用Rsyslog快速方便的收集Nginx日志</h1>
      

      <blockquote>
<p>常规的日志收集方案中Client端都需要额外安装一个Agent来收集日志，例如logstash、filebeat等，额外的程序也就意味着环境的复杂，资源的占用，有没有一种方式是不需要额外安装程序就能实现日志收集呢？Rsyslog就是你要找的答案！</p>
</blockquote>
<h1 id="rsyslog">Rsyslog</h1>
<p>Rsyslog是高速的日志收集处理服务，它具有高性能、安全可靠和模块化设计的特点，能够接收来自各种来源的日志输入（例如：file，tcp，udp，uxsock等），并通过处理后将结果输出的不同的目的地（例如：mysql，mongodb，elasticsearch，kafka等），每秒处理日志量能够超过百万条。</p>
<p>Rsyslog作为syslog的增强升级版本已经在各linux发行版<strong>默认安装</strong>了，无需额外安装。</p>
<h1 id="nginx">收集Nginx日志</h1>
<p>ELK通过Rsyslog收集日志流程图如下：
<img alt="" src="https://blz.nosdn.127.net/sre/images/20180828.00.jpg" /></p>
<ol>
<li>处理流程为：Nginx --syslog--&gt; Rsyslog --omkafka--&gt; Kafka --&gt; Logstash --&gt; Elasticsearch --&gt; Kibana</li>
<li>Nginx产生日志通过syslog系统服务传给Rsyslog服务端，Rsyslog接收到日志后通过omkafka模块将日志写入Kafka，Logstash读取Kafka队列然后写入Elasticsearch，用户通过Kibana检索Elasticsearch里存储的日志</li>
<li>Rsyslog服务系统自带无需安装，所以整个流程中客户端不需要额外安装应用</li>
<li>服务端虽然Rsyslog也已安装，但默认没有omkafka模块，如果需要Rsyslog写入Kafka需要先安装这个模块</li>
<li>omkafka模块在rsyslog v8.7.0之后的版本才支持，所以需要先通过<code>rsyslogd -v</code>命令查看rsyslog版本，如果版本较低则需要升级</li>
</ol>
<h2 id="rsyslog_1">Rsyslog升级</h2>
<p>1.添加rsyslog源的key</p>
<pre class="codehilite"><code># apt-key adv --recv-keys --keyserver keys.gnupg.net AEF0CF8E</code></pre>


<p>2.添加rsyslog源地址</p>
<pre class="codehilite"><code>echo &quot;deb http://debian.adiscon.com/v8-stable wheezy/&quot; &gt;&gt; /etc/apt/sources.list
echo &quot;deb-src http://debian.adiscon.com/v8-stable wheezy/&quot; &gt;&gt; /etc/apt/sources.list</code></pre>


<p>3.升级rsyslog服务</p>
<pre class="codehilite"><code># apt-get update &amp;&amp; apt-get -y install rsyslog</code></pre>


<h2 id="omkafka">添加omkafka模块</h2>
<p>1.安装编译工具，下边autoreconf需要用到，不然无法生成configure文件</p>
<pre class="codehilite"><code># apt-get -y install pkg-config autoconf automake libtool unzip</code></pre>


<p>2.omkafka需要安装一堆的依赖包</p>
<pre class="codehilite"><code># apt-get -y install libdbi-dev libmysqlclient-dev postgresql-client libpq-dev  libnet-dev   librdkafka-dev   libgrok-dev libgrok1 libgrok-dev libpcre3-dev libtokyocabinet-dev libglib2.0-dev  libmongo-client-dev  libhiredis-dev
# apt-get -y install libestr-dev libfastjson-dev uuid-dev liblogging-stdlog-dev libgcrypt-dev
# apt-get -y install flex bison librdkafka1 librdkafka-dev librdkafka1-dbg</code></pre>


<p>3.编译安装omkafka模块</p>
<pre class="codehilite"><code># mkdir tmp &amp;&amp; cd tmp

# git init
# git pull git@github.com:VertiPub/omkafka.git

# autoreconf -fvi
# ./configure --sbindir=/usr/sbin --libdir=/usr/lib --enable-omkafka &amp;&amp; make &amp;&amp; make install &amp;&amp; cd ..</code></pre>


<h2 id="rsyslognginx">Rsyslog收集nginx日志</h2>
<h5 id="clientnginx">Client端Nginx配置</h5>
<pre class="codehilite"><code>log_format  jsonlog '{'
    '&quot;host&quot;: &quot;$host&quot;,'
    '&quot;server_addr&quot;: &quot;$server_addr&quot;,'
    '&quot;http_x_forwarded_for&quot;:&quot;$http_x_forwarded_for&quot;,'
    '&quot;remote_addr&quot;:&quot;$remote_addr&quot;,'
    '&quot;time_local&quot;:&quot;$time_local&quot;,'
    '&quot;request_method&quot;:&quot;$request_method&quot;,'
    '&quot;request_uri&quot;:&quot;$request_uri&quot;,'
    '&quot;status&quot;:$status,'
    '&quot;body_bytes_sent&quot;:$body_bytes_sent,'
    '&quot;http_referer&quot;:&quot;$http_referer&quot;,'
    '&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,'
    '&quot;upstream_addr&quot;:&quot;$upstream_addr&quot;,'
    '&quot;upstream_status&quot;:&quot;$upstream_status&quot;,'
    '&quot;upstream_response_time&quot;:&quot;$upstream_response_time&quot;,'
    '&quot;request_time&quot;:$request_time'
'}';


access_log syslog:server=rsyslog.domain.com,facility=local7,tag=nginx_access_log,severity=info jsonlog;</code></pre>


<p>1.Nginx在<strong>v1.10之后</strong>的版本才支持syslog的方式处理日志，请确保你的Nginx版本高于1.10</p>
<p>2.为了降低logstash的处理压力，同时也为了降低整个配置的复杂度，我们nginx的日志直接采用json格式</p>
<p>3.抛弃文本文件记录nginx日志，改用syslog直接将日志传输到远端的rsyslog服务器，以便我们后续的处理；这样做的另一个非常重要的好处是我们再也无需考虑nginx日志的分割和定期删除问题（一般我们为了方便管理通常会采用logrotate服务来对日志进行按天拆分和定期删除,以免磁盘被占满）</p>
<p>4.access_log直接输出到syslog服务，各参数解释如下：
- <strong>syslog</strong>：指明日志用syslog服务接收
- <strong>server</strong>：接收syslog发送日志的Rsyslog服务端地址，默认使用udp协议，端口是514
- <strong>facility</strong>：指定记录日志消息的类型，例如认证类型auth、计划任务cron、程序自定义的local0-7等，没有什么特别的含义，不必深究，默认的值是local7
- <strong>tag</strong>：给日志添加一个tag，主要是为了方便我们在服务端区分是哪个服务或者client传来的日志，例如我们这里给了tag：<code>nginx_access_log</code>，如果有多个服务同时都写日志给rsyslog，且配置了不通的tag，在rsyslog服务端就可以根据这个tag找出哪些是nginx的日志
- <strong>severity</strong>：定义日志的级别，例如debug，info，notice等，默认是error</p>
<h5 id="serverrsyslog">Server端Rsyslog配置</h5>
<pre class="codehilite"><code># cat /etc/rsyslog.d/rsyslog_nginx_kafka_cluster.conf 
module(load=&quot;imudp&quot;)
input(type=&quot;imudp&quot; port=&quot;514&quot;)

# nginx access log ==&gt; rsyslog server(local) ==&gt; kafka
module(load=&quot;omkafka&quot;)

template(name=&quot;nginxLog&quot; type=&quot;string&quot; string=&quot;%msg%&quot;)

if $inputname == &quot;imudp&quot; then {
    if ($programname == &quot;nginx_access_log&quot;) then
        action(type=&quot;omkafka&quot;
            template=&quot;nginxLog&quot;
            broker=[&quot;10.82.9.202:9092&quot;,&quot;10.82.9.203:9092&quot;,&quot;10.82.9.204:9092&quot;]
            topic=&quot;rsyslog_nginx&quot;
            partitions.auto=&quot;on&quot;
            confParam=[
                &quot;socket.keepalive.enable=true&quot;
            ]
        )
}

:rawmsg, contains, &quot;nginx_access_log&quot; ~</code></pre>


<p>1.在rsyslog.d目录下添加一个专门处理nginx日志的配置文件</p>
<p>2.rsyslog配置文件重要配置解释如下：
- <strong>module</strong>：加载模块，这里我们需要加载imudp模块来接收nginx服务器syslog发过来的日志数据，也需要加载omkafka模块来将日志写入到kafka
- <strong>input</strong>：开启udp协议，端口514，也可以同时开启tcp协议，两者可以共存
- <strong>template</strong>：定义一个模板，名字叫nginxLog，模板里可以定义日志的格式，因为我们传的已经是json了，不需要再匹配格式，所以这里不额外定义，注意模板名字要唯一
- <strong>action</strong>：在匹配到inputname为<code>imudp</code>且programname为<code>nginx_access_log</code>（就是我们上边nginx配置里边的tag）之后的处理方式，这里的配置为匹配到的日志通过omkafka模块写入kafka集群，还有一些关于omkafka更详细的配置参考上边给出的omkafka模块官方文档
- <strong>:rawmsg, contains</strong>：最后这一行的意思是忽略包含<code>nginx_access_log</code>的日志，没有这一行的话rsyslog服务默认会把所有日志都记录到message里边一份，我们已经把日志输出到kafka了，本地就没必要再记录了</p>
<p>3.omkafka模块检查kafka里边topic是否存在，如果不存在则创建，无需手动创建kafka的topic</p>
<h5 id="serverlogstash">Server端logstash配置</h5>
<pre class="codehilite"><code>input {
    kafka {
        bootstrap_servers =&gt; &quot;10.82.9.202:9092,10.82.9.203:9092,10.82.9.204:9092&quot;
        topics =&gt; [&quot;rsyslog_nginx&quot;]
    }
}

filter {
    mutate {
        gsub =&gt; [&quot;message&quot;, &quot;\\x&quot;, &quot;\\\x&quot;]
    }

    json {
        source =&gt; &quot;message&quot;
    }

    date {
        match =&gt; [&quot;time_local&quot;,&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;]
        target =&gt; &quot;@timestamp&quot;
    }

}

output {
    elasticsearch {
        hosts =&gt; [&quot;10.82.9.205&quot;, &quot;10.82.9.206&quot;, &quot;10.82.9.207&quot;]
        index =&gt; &quot;rsyslog-nginx-%{+YYYY.MM.dd}&quot;
    }
}</code></pre>


<p>重要配置参数解释如下：
- <strong>input</strong>：配置kafka的集群地址和topic名字
- <strong>filter</strong>：一些过滤策略，因为传入kafka的时候是json格式，所以不需要额外处理，唯一需要注意的是如果日志中有中文，例如url中有中文内容时需要替换<code>\\x</code>，不然json格式会报错
- <strong>output</strong>：配置ES服务器集群的地址和index，index自动按天分割</p>
<h5 id="_1">联调测试</h5>
<p>配置完成后分别重启rsyslog服务和nginx服务，访问nginx产生日志</p>
<p>1.查看kafka是否有正常生成topic</p>
<pre class="codehilite"><code># bin/kafka-topics.sh --list --zookeeper 127.0.0.1:2181
__consumer_offsets
rsyslog_nginx</code></pre>


<p>2.查看topic是否能正常接收日志</p>
<pre class="codehilite"><code># bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic rsyslog_nginx
{&quot;host&quot;: &quot;domain.com&quot;,&quot;server_addr&quot;: &quot;172.17.0.2&quot;,&quot;http_x_forwarded_for&quot;:&quot;58.52.198.68&quot;,&quot;remote_addr&quot;:&quot;10.120.89.84&quot;,&quot;time_local&quot;:&quot;28/Aug/2018:14:26:00 +0800&quot;,&quot;request_method&quot;:&quot;GET&quot;,&quot;request_uri&quot;:&quot;/&quot;,&quot;status&quot;:200,&quot;body_bytes_sent&quot;:1461,&quot;http_referer&quot;:&quot;-&quot;,&quot;http_user_agent&quot;:&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&quot;,&quot;upstream_addr&quot;:&quot;-&quot;,&quot;upstream_status&quot;:&quot;-&quot;,&quot;upstream_response_time&quot;:&quot;-&quot;,&quot;request_time&quot;:0.000}</code></pre>


<p>3.kibana添加index，查看Elasticsearch中是否有数据，如果前两步都正常，kibana搜不到index或index没有数据，多半是index名字写错了之类的基础问题，仔细检查</p>
<h2 id="kibana">kibana查询展示</h2>
<ul>
<li>打开Kibana添加<code>rsyslog-nginx-*</code>的Index，并选择timestamp，创建Index Pattern</li>
</ul>
<p><img alt="" src="https://blz.nosdn.127.net/sre/images/20180828.02.png" /></p>
<ul>
<li>进入Discover页面，可以很直观的看到各个时间点请求量的变化，根据左侧Field实现简单过滤，例如我们想查看所有访问状态为404的uri，可以点击request_uri和status后边的add，这两项的内容将出现在右侧，然后点击status下边404状态码后边的加号，则只查看状态为404的请求，点击上方auto-refresh可以设置页面自动刷新时间</li>
</ul>
<p><img alt="" src="https://blz.nosdn.127.net/sre/images/20180828.03.png" /></p>
<ul>
<li>通过各种条件的组合查询可以实现各种各样的需求，例如每秒请求、带宽占用、异常比例、慢响应、TOP IP、TOP URL等等各种情况，并且可以通过Visualize很方便的将这些信息绘制图标，生成Dashboard保存</li>
</ul>
<p><img alt="" src="https://blz.nosdn.127.net/sre/images/20180828.04.png" /></p>
<h1 id="_2">写在最后</h1>
<ol>
<li>Nginx的access log绝对是网站的一个宝藏，通过日志量的变化可以知道网站的流量情况，通过对status状态的分析可以知道我们提供服务的可靠性，通过对特定活动url的追踪可以实时了解活动的火爆程度，通过对某些条件的组合查询也能为网站运营提供建议和帮助，从而使我们的网站更友好更易用</li>
<li>Rsyslog服务的单点问题可以通过部署多个Rsyslog服务过三层负载来保证高可用，不过以我们的经验来说rsyslog服务还是很稳定的，跑了一年多，每分钟日志处理量在20w左右，没有出现过宕机情况，不想这么复杂的话可以写个check rsyslog服务状态的脚本跑后台，挂了自动拉起来</li>
<li>整个过程中我们使用了UDP协议，第一是因为Nginx日志的syslog模式默认支持的就是UDP协议，翻了官网没找到支持TCP的方式，我想这也是考虑到UDP协议的性能要比TCP好的多，第二也考虑到如果使用TCP遇到网络不稳定的情况下可能会不停的重试或等待，影响到Nginx的稳定。对于因为内容过长超过以太网数据帧长度的问题暂时没有遇到</li>
</ol>
<hr />
<p><img alt="长按关注公众号查看更多原创文章" src="http://blz.nos.netease.com/sre/wx.qrcode.jpg" /></p>
<p>如果你觉得文章对你有帮助，请转发分享给更多的人。如果你觉得读的不尽兴，推荐阅读以下文章：
- <a href="https://ops-coffee.cn/s/umH7ImZZVhdfgMdZ3Hz5fA">ELK构建MySQL慢日志收集平台详解</a>
- <a href="https://ops-coffee.cn/s/GATfwNETo_aGsJHZdV5YzQ">中小团队基于Docker的devops实践</a></p>
      </section>

      <aside id="sidebar">
        <button onclick="javascrtpt:window.open('/search.html')" style="width:100%;cursor:pointer">站内搜索</button>

        <blockquote class="route">作者介绍</blockquote>
        <p>37丫37，现居上海，专职运维，涉猎广泛，重原则，有态度</p>
        <p>运营公众号【运维咖啡吧】，这是一个不落俗套坚持初心的公众号，一个你不可错过的公众号</p>
        <img border="0" src="https://blz.nosdn.127.net/sre/posts/images/z-qrcode.jpg" width="100%" height="100%" alt="ops-coffee">
        <p>欢迎关注，后台回复“小二”加我微信，聊技术，谈理想，悟人生</p>

        <blockquote class="route">归档列表</blockquote>
        <div class="sidebar-list"><a href="/s"> 精选文章列表</a></div>
        <div class="sidebar-list"><a href="/t/"> 日常运维记录</a></div>
        <div class="sidebar-list"><a href="/webssh"> WebSSH系列</a></div>

        <blockquote class="route">锟斤拷锟斤</blockquote>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <!-- sidebar -->
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-8944257246828217"
             data-ad-slot="1313935804"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
        <script>
             (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      </aside>
    </div>
  </div>

  <footer class="footer">
    <div class="inner">
      <div class="copy"> © 2019 ops-coffee</div>

      <div class="link">
        <a href="#sidebar" onclick="if(confirm('扫描二维码，关注我吧')==false)return false;" title="关于本站" target="">关于本站</a>
        <a href="/friends" title="友情链接" target="_blank">友情链接</a>
      </div>
    </div>
  </footer>
</body>

</html>